## There is no Free Lunch!

This document is for informational purposes only. Little or no conclusion will be drawn from here, 
it is just interesting data that I want to share.
Like all performance tests, local variables will always change the results.

Once we have a native proxy image, compiled via GraalVM, and an image of the user function compiled in a JVM, 
we have a good opportunity to perform some general performance measures.
Our docker image based on Springboot support on Cloudstate is generated by the Google Jib plug-in and has as its base 
layer an image adoptedpenjdk/openjdk8-openj9:alpine-slim.

We added some parameters recommended by the OpenJ9 documentation for a faster startup and a smaller footprint:
```xml
<jvmFlag> -XshareClasses </jvmFlag>
<jvmFlag> -Xquickstart </jvmFlag>
```

The whole plugin is configured this way:

```xml
<plugin>
    <groupId> com.google.cloud.tools </groupId>
    <artifactId> jib-maven-plugin </artifactId>
    <version> 1.7.0 </version>
    <executions>
        <execution>
            <phase>package</phase>
            <goals>
                <goal>build</goal>
            </goals>
        </execution>
    </executions>
    <configuration>
        <from>
            <image>adoptopenjdk/openjdk8-openj9:alpine-slim</image>
            <credHelper> </credHelper>
        </from>
        <to>
            <image>sleipnir/cloudstate-boot-example</image>
            <credHelper> </credHelper>
            <tags>
                <tag>${project.version}</tag>
            </tags>
        </to>
        <container>
            <mainClass>${main.class}</mainClass>
            <jvmFlags>
                <jvmFlag>-XshareClasses</jvmFlag>
                <jvmFlag>-Xquickstart</jvmFlag>
                <jvmFlag>-XX:+UseG1GC</jvmFlag>
                <jvmFlag>-XX:+UseStringDeduplication</jvmFlag>
            </jvmFlags>
            <ports>
                <port>8080</port>
            </ports>
        </container>
    </configuration>
</plugin>
```

This configuration will generate a modest docker image, that is, neither too large nor too small:

```shell script
# docker images
REPOSITORY                                      TAG                 IMAGE ID            CREATED             SIZE
sleipnir/cloudstate-boot-example                0.4.3               eccd2e37de44        50 years ago        161MB
cloudstateio/cloudstate-proxy-native-dev-mode   latest              fed44820c73c        4 months ago        477MB

```

In turn, the proxy we use is a native image compiled via GraalVM. As we saw above, the generated image is a little big (477MB) 
and could be optimized to be a little better according to this discussion [here](https://github.com/cloudstateio/cloudstate/pull/207#issuecomment-601248956).

The exception of this detail of the image size is "known" that native images have a faster boot time during boot and in 
general have a smaller footprint of memory during execution.

Well, it does start significantly faster than similar JVM application, but at the end, when the application runs f
or a long time, the just-in-time compiler can actually outperform the AOT one. 

As the helidon.io team puts it:

“On the other hand, everything is always a tradeoff. Long running applications on traditional JVMs are still 
demonstrating better performance than GraalVM native executables due to runtime optimization. The key word here 
is long-running; for short-running applications like 'serverless **stateless** functions', native executables have a performance advantage. 
So, you need to decide yourself between fast startup time and small size (and the additional step of building the native executable) 
versus better performance for long-running applications. ”

"***The stateless in bold it's author's note :D***"

## Now that we have some context let's go to the tests

First I wrote a short test via Gatling framework.
We see in this test that we are going to test a very simple feature of ShoppingCart example and that we are not doing much.

Gatling test code:

```scala
package io.cloudstate.springboot.example

import scala.concurrent.duration._

import io.gatling.core.Predef._
import io.gatling.core.structure.{ChainBuilder, ScenarioBuilder}
import io.gatling.http.Predef._
import io.gatling.http.protocol.HttpProtocolBuilder

class LoadTest extends Simulation {

  val httpProtocol: HttpProtocolBuilder = http
    .baseUrl("http://localhost:9000")

  object GetCartResource {
    val get: ChainBuilder = exec(http("GetUserCart")
      .get("/carts/adriano/items"))
  }

  val shoppingCartScenario: ScenarioBuilder = scenario("RampUpUsers")
    .exec(GetCartResource.get)

  setUp(shoppingCartScenario.inject(
    incrementUsersPerSec(20)
      .times(5)
      .eachLevelLasting(5 seconds)
      .separatedByRampsLasting(5 seconds)
      .startingFrom(20)
  )).protocols(httpProtocol)
    .assertions(global.successfulRequests.percent.is(100))
}

```

Then what we have to do is start our compiled user role. And run our test with **mvn gatling:test**

Cloudstate Springboot startup:

![cloudstate boot](/docs/img/cloudstate-boot-perf-boot-wow.png)

Cloudstate CLI starting Proxy:

![cloudstate proxy run](/docs/img/cloudstate-cli-boot-perf.png)

Tests results:

![cloudstate gatling](/docs/img/cloudstate-gatling.png)

![gatling 1](/docs/img/gatling-perf-1.png)

![gatling 2](/docs/img/gatling-perf-2.png)

![gatling 3](/docs/img/gatling-perf-3.png)

![gatling 4](/docs/img/gatling-perf-4.png)

Cloudstate Springboot User function:

![cloudstate perf](/docs/img/cloudstate-perf-user-paused.png)

![cloudstate cpug](/docs/img/cloudstate-user-perf-ok.png)

![cloudstate memory](/docs/img/cloudstate-user-perf-memory.png)

Cloudsatate Proxy:

![proxy cpu](/docs/img/proxy-cpu.png)

![proxy memory](/docs/img/proxy-memory.png)

Click on the image below to see the video of the docker statistics:

[![docker stats](/docs/img/docker-stats.png)](https://asciinema.org/a/H8IzG9tdEsgPqkZiXfrQ6UN3D)

Well the graphics and evidence speak for themselves, but in summary we can see that the use of cpu at rest for both 
applications is very good, as well as the memory consumption is acceptable. However, this changes a little when we start 
running the test, we can see some CPU spikes mainly in the Proxy, nothing I didn't expect from an application compiled in GraalVM. 
But what really surprised us was the increasing memory usage of the Proxy, which doesn't seem 
to complain about any cleaning during and after the test. Undoubtedly, something to be investigated since it is to be expected 
that in "pay for what you use" environments you will not want to be consuming memory without traffic.

In terms of performance the test was excellent because, in addition to all requests having been successfully executed, 
the throughtput was spectacular as we can see in the Gatling report.


I added a [ticket](https://github.com/cloudstateio/cloudstate/issues/235) to Cloudstate and I hope these insights can help the platform evolve.